{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "759b0270-88b3-4891-9ea9-a1816ad5f83e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in /opt/anaconda3/lib/python3.11/site-packages (2.17.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /opt/anaconda3/lib/python3.11/site-packages (from tensorflow) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /opt/anaconda3/lib/python3.11/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in /opt/anaconda3/lib/python3.11/site-packages (from tensorflow) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /opt/anaconda3/lib/python3.11/site-packages (from tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /opt/anaconda3/lib/python3.11/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=3.10.0 in /opt/anaconda3/lib/python3.11/site-packages (from tensorflow) (3.11.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /opt/anaconda3/lib/python3.11/site-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in /opt/anaconda3/lib/python3.11/site-packages (from tensorflow) (0.4.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /opt/anaconda3/lib/python3.11/site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: packaging in /opt/anaconda3/lib/python3.11/site-packages (from tensorflow) (23.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /opt/anaconda3/lib/python3.11/site-packages (from tensorflow) (3.20.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /opt/anaconda3/lib/python3.11/site-packages (from tensorflow) (2.31.0)\n",
      "Requirement already satisfied: setuptools in /opt/anaconda3/lib/python3.11/site-packages (from tensorflow) (68.2.2)\n",
      "Requirement already satisfied: six>=1.12.0 in /opt/anaconda3/lib/python3.11/site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /opt/anaconda3/lib/python3.11/site-packages (from tensorflow) (2.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /opt/anaconda3/lib/python3.11/site-packages (from tensorflow) (4.9.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /opt/anaconda3/lib/python3.11/site-packages (from tensorflow) (1.14.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/anaconda3/lib/python3.11/site-packages (from tensorflow) (1.65.2)\n",
      "Requirement already satisfied: tensorboard<2.18,>=2.17 in /opt/anaconda3/lib/python3.11/site-packages (from tensorflow) (2.17.0)\n",
      "Requirement already satisfied: keras>=3.2.0 in /opt/anaconda3/lib/python3.11/site-packages (from tensorflow) (3.4.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /opt/anaconda3/lib/python3.11/site-packages (from tensorflow) (0.37.1)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /opt/anaconda3/lib/python3.11/site-packages (from tensorflow) (1.26.4)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /opt/anaconda3/lib/python3.11/site-packages (from astunparse>=1.6.0->tensorflow) (0.41.2)\n",
      "Requirement already satisfied: rich in /opt/anaconda3/lib/python3.11/site-packages (from keras>=3.2.0->tensorflow) (13.3.5)\n",
      "Requirement already satisfied: namex in /opt/anaconda3/lib/python3.11/site-packages (from keras>=3.2.0->tensorflow) (0.0.8)\n",
      "Requirement already satisfied: optree in /opt/anaconda3/lib/python3.11/site-packages (from keras>=3.2.0->tensorflow) (0.12.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow) (2024.7.4)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/anaconda3/lib/python3.11/site-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/anaconda3/lib/python3.11/site-packages (from tensorboard<2.18,>=2.17->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /opt/anaconda3/lib/python3.11/site-packages (from tensorboard<2.18,>=2.17->tensorflow) (2.2.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /opt/anaconda3/lib/python3.11/site-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow) (2.1.3)\n",
      "Requirement already satisfied: markdown-it-py<3.0.0,>=2.2.0 in /opt/anaconda3/lib/python3.11/site-packages (from rich->keras>=3.2.0->tensorflow) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/anaconda3/lib/python3.11/site-packages (from rich->keras>=3.2.0->tensorflow) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/anaconda3/lib/python3.11/site-packages (from markdown-it-py<3.0.0,>=2.2.0->rich->keras>=3.2.0->tensorflow) (0.1.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "651e1cee-7345-4bef-a7f0-e287e1470f46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.17.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8a23a187-d92d-467d-8323-5b971d58600a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import urllib.request\n",
    "from konlpy.tag import Okt\n",
    "from tqdm import tqdm\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5caa15eb-7b1c-4460-9cb3-d2dd3445fa8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = 'blog_raw.csv'\n",
    "df = pd.read_csv(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3ec4d456-e86a-444f-b1ec-1a4b036b7dd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ë„¤ì´ë²„ ë¸”ë¡œê·¸ ë¦¬ë·° ê°œìˆ˜ :  801\n"
     ]
    }
   ],
   "source": [
    "blog_text = pd.read_csv('blog_raw.csv', sep=',')\n",
    "print('ë„¤ì´ë²„ ë¸”ë¡œê·¸ ë¦¬ë·° ê°œìˆ˜ : ',len(blog_text)) #ë¦¬ë·° ê°œìˆ˜ ì¶œë ¥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d8ea0404-e8c3-49c5-85b7-69bbcb1dc9dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>nick</th>\n",
       "      <th>date</th>\n",
       "      <th>title</th>\n",
       "      <th>contents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://blog.naver.com/2lmg/223531152299</td>\n",
       "      <td>ì¡ë‹¬êµ¬ë¦¬</td>\n",
       "      <td>2024-07-31</td>\n",
       "      <td>ì¼€ì´ì¹´êµ¬ë§¤í›„ê¸°5íƒ„</td>\n",
       "      <td>#ì¼€ì´ì¹´ #ì¼€ì´ì¹´ì›ŒëŸ°í‹° #ì¬ìƒë°œì „ê¸°\\nêµ­ì‚°ì°¨ì˜ì¥ì ì¤‘ í•˜ë‚˜ëŠ” ì‹ ì†ì •í™•í•œ ì •ë¹„ì¸ê±°ê°™ë‹¤\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://blog.naver.com/2lmg/223530515494</td>\n",
       "      <td>ì¡ë‹¬êµ¬ë¦¬</td>\n",
       "      <td>2024-07-30</td>\n",
       "      <td>ì¼€ì´ì¹´êµ¬ë§¤í›„ê¸°4íƒ„ ì¼€ì´ì¹´ì›ŒëŸ°í‹°ì— í•œê³„ì </td>\n",
       "      <td>#ì¼€ì´ì¹´ #ì¼€ì´ì¹´ì›ŒëŸ°í‹° #ì œë„¤ë ˆì´í„°\\nì¼ë‹¨ì€ ì¼€ì´ì¹´ì— ì ‘ìˆ˜í•˜ëŠ”ê³³ì—ì„œ\\nì ‘ìˆ˜í–ˆì„ë•Œ ì „...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://blog.naver.com/sj0_0410/223530026017</td>\n",
       "      <td>ì§€ì˜</td>\n",
       "      <td>2024-07-30</td>\n",
       "      <td>20ëŒ€ ì²«ì°¨êµ¬ë§¤ ì¼€ì´ì¹´ì—ì„œ ì¤‘ê³ ì°¨ ìŠ¤íŒŒí¬ LTZ êµ¬ë§¤ 1ë…„ í›„ê¸° ì´ë¹„ìš©,ì¼€ì´ì¹´ì›ŒëŸ°í‹° ë“±</td>\n",
       "      <td>ì•ˆë…•í•˜ì„¸ìš”\\nì˜¤ëŠ˜ì€ ì¼€ì´ì¹´ì—ì„œ ì²« ì¤‘ê³ ì°¨ êµ¬ë§¤\\nê²½í—˜ì„ í¬ìŠ¤íŒ…í•˜ë ¤ê³  í•©ë‹ˆë‹¤\\nì €ëŠ” ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://blog.naver.com/kcar-official/223530662750</td>\n",
       "      <td>K Car ì¼€ì´ì¹´</td>\n",
       "      <td>2024-07-30</td>\n",
       "      <td>ì§‘ ì•ê¹Œì§€ K5í•˜ì´ë¸Œë¦¬ë“œ ë°°ì†¡í•´ ì£¼ëŠ” ì¼€ì´ì¹´ í™ˆì„œë¹„ìŠ¤ êµ¿! ì¤‘ê³ ì°¨êµ¬ë§¤ í¸í•´ì„œ ì¢‹ì•˜ì–´ìš”.</td>\n",
       "      <td>ğŸš—ì†Œ* ë‹˜ì˜ í›„ê¸° ì „ë¬¸ ë³´ëŸ¬ ê°€ê¸°ğŸš—\\ní‰ì†Œì— ì°¨ë¥¼ ì •ë§ êµ¬ë§¤í•˜ê³  ì‹¶ì—ˆëŠ”ë°ìš”.\\nì¤‘ê³ ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://blog.naver.com/2lmg/223529372421</td>\n",
       "      <td>ì¡ë‹¬êµ¬ë¦¬</td>\n",
       "      <td>2024-07-29</td>\n",
       "      <td>ì¼€ì´ì¹´ êµ¬ë§¤í›„ê¸° 3íƒ„</td>\n",
       "      <td>#ì¼€ì´ì¹´ #ì¼€ì´ì¹´ì›ŒëŸ°í‹° #ê·¸ëœì €hg\\nì¼ë‹¨ ì°¨ëŸ‰êµ¬ë§¤í•˜ê³  ë‚˜ì„œ í•œë‹¬ì •ë„ 2000í‚¬ë¡œë¯¸...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 url       nick        date  \\\n",
       "0           https://blog.naver.com/2lmg/223531152299       ì¡ë‹¬êµ¬ë¦¬  2024-07-31   \n",
       "1           https://blog.naver.com/2lmg/223530515494       ì¡ë‹¬êµ¬ë¦¬  2024-07-30   \n",
       "2       https://blog.naver.com/sj0_0410/223530026017         ì§€ì˜  2024-07-30   \n",
       "3  https://blog.naver.com/kcar-official/223530662750  K Car ì¼€ì´ì¹´  2024-07-30   \n",
       "4           https://blog.naver.com/2lmg/223529372421       ì¡ë‹¬êµ¬ë¦¬  2024-07-29   \n",
       "\n",
       "                                              title  \\\n",
       "0                                         ì¼€ì´ì¹´êµ¬ë§¤í›„ê¸°5íƒ„   \n",
       "1                             ì¼€ì´ì¹´êµ¬ë§¤í›„ê¸°4íƒ„ ì¼€ì´ì¹´ì›ŒëŸ°í‹°ì— í•œê³„ì    \n",
       "2  20ëŒ€ ì²«ì°¨êµ¬ë§¤ ì¼€ì´ì¹´ì—ì„œ ì¤‘ê³ ì°¨ ìŠ¤íŒŒí¬ LTZ êµ¬ë§¤ 1ë…„ í›„ê¸° ì´ë¹„ìš©,ì¼€ì´ì¹´ì›ŒëŸ°í‹° ë“±   \n",
       "3  ì§‘ ì•ê¹Œì§€ K5í•˜ì´ë¸Œë¦¬ë“œ ë°°ì†¡í•´ ì£¼ëŠ” ì¼€ì´ì¹´ í™ˆì„œë¹„ìŠ¤ êµ¿! ì¤‘ê³ ì°¨êµ¬ë§¤ í¸í•´ì„œ ì¢‹ì•˜ì–´ìš”.   \n",
       "4                                       ì¼€ì´ì¹´ êµ¬ë§¤í›„ê¸° 3íƒ„   \n",
       "\n",
       "                                            contents  \n",
       "0  #ì¼€ì´ì¹´ #ì¼€ì´ì¹´ì›ŒëŸ°í‹° #ì¬ìƒë°œì „ê¸°\\nêµ­ì‚°ì°¨ì˜ì¥ì ì¤‘ í•˜ë‚˜ëŠ” ì‹ ì†ì •í™•í•œ ì •ë¹„ì¸ê±°ê°™ë‹¤\\...  \n",
       "1  #ì¼€ì´ì¹´ #ì¼€ì´ì¹´ì›ŒëŸ°í‹° #ì œë„¤ë ˆì´í„°\\nì¼ë‹¨ì€ ì¼€ì´ì¹´ì— ì ‘ìˆ˜í•˜ëŠ”ê³³ì—ì„œ\\nì ‘ìˆ˜í–ˆì„ë•Œ ì „...  \n",
       "2  ì•ˆë…•í•˜ì„¸ìš”\\nì˜¤ëŠ˜ì€ ì¼€ì´ì¹´ì—ì„œ ì²« ì¤‘ê³ ì°¨ êµ¬ë§¤\\nê²½í—˜ì„ í¬ìŠ¤íŒ…í•˜ë ¤ê³  í•©ë‹ˆë‹¤\\nì €ëŠ” ...  \n",
       "3  ğŸš—ì†Œ* ë‹˜ì˜ í›„ê¸° ì „ë¬¸ ë³´ëŸ¬ ê°€ê¸°ğŸš—\\ní‰ì†Œì— ì°¨ë¥¼ ì •ë§ êµ¬ë§¤í•˜ê³  ì‹¶ì—ˆëŠ”ë°ìš”.\\nì¤‘ê³ ...  \n",
       "4  #ì¼€ì´ì¹´ #ì¼€ì´ì¹´ì›ŒëŸ°í‹° #ê·¸ëœì €hg\\nì¼ë‹¨ ì°¨ëŸ‰êµ¬ë§¤í•˜ê³  ë‚˜ì„œ í•œë‹¬ì •ë„ 2000í‚¬ë¡œë¯¸...  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blog_text.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1ee6b5af-1d20-4b61-bb0a-a822409e4d65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: emoji in /opt/anaconda3/lib/python3.11/site-packages (2.12.1)\n",
      "Requirement already satisfied: typing-extensions>=4.7.0 in /opt/anaconda3/lib/python3.11/site-packages (from emoji) (4.9.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d9e0e85f-8a46-4c0c-a269-e439f81814db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì´ëª¨ì§€ê°€ ì œê±°ëœ ë¸”ë¡œê·¸ ë¦¬ë·°ë¥¼ 'blog_no_emojis.csv' íŒŒì¼ë¡œ ì €ì¥í–ˆìŠµë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "import emoji\n",
    "import pandas as pd\n",
    "\n",
    "# CSV íŒŒì¼ ì½ê¸°\n",
    "df = pd.read_csv('blog_raw.csv')\n",
    "\n",
    "# ì´ëª¨ì§€ ì œê±° í•¨ìˆ˜ ì •ì˜\n",
    "def remove_emojis(title):\n",
    "    return emoji.replace_emoji(title, replace='')\n",
    "\n",
    "# ì´ëª¨ì§€ ì œê±° í•¨ìˆ˜ ì •ì˜-2\n",
    "def remove_emojis(contents):\n",
    "    return emoji.replace_emoji(contents, replace='')\n",
    "\n",
    "# íŠ¹ìˆ˜ë¬¸ì ì œê±° í•¨ìˆ˜ ì •ì˜\n",
    "def remove_special_characters(title):\n",
    "    return re.sub(r'[\\^~!.,?â™¡â€¥/-_*o()âœ¿â—¡â€¿â—¡]', '', title)\n",
    "\n",
    "# íŠ¹ìˆ˜ë¬¸ì ì œê±° í•¨ìˆ˜ ì •ì˜-2\n",
    "def remove_special_characters(contents):\n",
    "    return re.sub(r'[\\^~!.,?â™¡â€¥/-_*o()âœ¿â—¡â€¿â—¡]', '', contents)\n",
    "\n",
    "# í…ìŠ¤íŠ¸ ì œê±° í•¨ìˆ˜ ì •ì˜\n",
    "def remove_specific_chars(title):\n",
    "    return re.sub(r'[ã…¡ã…œã… ã…ã…‹]', '', title)\n",
    "\n",
    "# í…ìŠ¤íŠ¸ ì œê±° í•¨ìˆ˜ ì •ì˜-2\n",
    "def remove_specific_chars(contents):\n",
    "    return re.sub(r'[ã…¡ã…œã… ã…ã…‹]', '', contents)\n",
    "\n",
    "# í…ìŠ¤íŠ¸ ì œê±° í•¨ìˆ˜ ì •ì˜-3\n",
    "def remove_specific_chars(contents):\n",
    "    return re.sub(r'[ì¬ìƒ, ì¢‹ì•„ìš”]', '', contents)\n",
    "\n",
    "# 'title' ì—´ì—ì„œ ì´ëª¨ì§€ ì œê±°\n",
    "df['title'] = df['title'].apply(remove_emojis)\n",
    "\n",
    "# 'title' ì—´ì—ì„œ íŠ¹ìˆ˜ë¬¸ì ì œê±°\n",
    "df['title'] = df['title'].apply(remove_special_characters)\n",
    "\n",
    "# 'title' ì—´ì—ì„œ 'ã…œã…œ', 'ã…¡ã…¡' í…ìŠ¤íŠ¸ ì œê±°\n",
    "df['title'] = df['title'].apply(remove_specific_chars)\n",
    "\n",
    "# 'contents' ì—´ì—ì„œ ì´ëª¨ì§€ ì œê±°\n",
    "df['contents'] = df['contents'].apply(remove_emojis)\n",
    "\n",
    "# 'contents' ì—´ì—ì„œ íŠ¹ìˆ˜ë¬¸ì ì œê±°\n",
    "df['contents'] = df['contents'].apply(remove_special_characters)\n",
    "\n",
    "# 'contents' ì—´ì—ì„œ 'ã…œã…œ', 'ã…¡ã…¡' í…ìŠ¤íŠ¸ ì œê±°\n",
    "df['contents'] = df['contents'].apply(remove_specific_chars)\n",
    "\n",
    "# 'contents' ì—´ì—ì„œ ì¬ìƒ, ì¢‹ì•„ìš” í…ìŠ¤íŠ¸ ì œê±°\n",
    "df['contents'] = df['contents'].apply(remove_specific_chars)\n",
    "\n",
    "# ê²°ê³¼ ì €ì¥\n",
    "df.to_csv('blog_no_emojis.csv', index=False)\n",
    "\n",
    "print(\"ì´ëª¨ì§€ê°€ ì œê±°ëœ ë¸”ë¡œê·¸ ë¦¬ë·°ë¥¼ 'blog_no_emojis.csv' íŒŒì¼ë¡œ ì €ì¥í–ˆìŠµë‹ˆë‹¤.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "28e7f674-633e-45bd-a6f4-d14d1ab909db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì „ì²˜ë¦¬ëœ ë¸”ë¡œê·¸ ë¦¬ë·°ë¥¼ 'blog_number.csv' íŒŒì¼ë¡œ ì €ì¥í–ˆìŠµë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "import emoji\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# CSV íŒŒì¼ ì½ê¸°\n",
    "df = pd.read_csv('blog_raw.csv')\n",
    "\n",
    "# ì´ëª¨ì§€ ì œê±° í•¨ìˆ˜ ì •ì˜\n",
    "def remove_emojis(text):\n",
    "    return emoji.replace_emoji(text, replace='')\n",
    "\n",
    "# íŠ¹ìˆ˜ë¬¸ì ì œê±° í•¨ìˆ˜ ì •ì˜ (ìˆ«ì ìœ ì§€)\n",
    "def remove_special_characters(text):\n",
    "    return re.sub(r'[^\\w\\s0-9ê°€-í£]', '', text)\n",
    "\n",
    "# íŠ¹ì • í…ìŠ¤íŠ¸ ì œê±° í•¨ìˆ˜ ì •ì˜\n",
    "def remove_specific_chars(text):\n",
    "    return re.sub(r'[ã…¡ã…œã… ã…ã…‹]', '', text)\n",
    "\n",
    "# 'ì¬ìƒ', 'ì¢‹ì•„ìš”' í…ìŠ¤íŠ¸ ì œê±° í•¨ìˆ˜ ì •ì˜\n",
    "def remove_specific_words(text):\n",
    "    return re.sub(r'ì¬ìƒ|ì¢‹ì•„ìš”', '', text)\n",
    "\n",
    "# ì „ì²˜ë¦¬ í•¨ìˆ˜ ì ìš©\n",
    "for column in ['title', 'contents']:\n",
    "    df[column] = df[column].apply(remove_emojis)\n",
    "    df[column] = df[column].apply(remove_special_characters)\n",
    "    df[column] = df[column].apply(remove_specific_chars)\n",
    "    df[column] = df[column].apply(remove_specific_words)\n",
    "\n",
    "# ê²°ê³¼ ì €ì¥\n",
    "df.to_csv('blog_number.csv', index=False)\n",
    "\n",
    "print(\"ì „ì²˜ë¦¬ëœ ë¸”ë¡œê·¸ ë¦¬ë·°ë¥¼ 'blog_number.csv' íŒŒì¼ë¡œ ì €ì¥í–ˆìŠµë‹ˆë‹¤.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c819128-ba5b-4b93-89c1-a5c52f95268a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
